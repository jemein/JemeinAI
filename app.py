import gradio as gr
from transformers import AutoTokenizer, BertForQuestionAnswering
import torch

# Load Chinese QA model
model_name = "cgt/Roberta-wwm-ext-large-qa"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = BertForQuestionAnswering.from_pretrained(model_name)

# QA function
def answer_question(context, question):
    try:
        inputs = tokenizer.encode_plus(question, context, return_tensors="pt", truncation=True)
        input_ids = inputs["input_ids"].tolist()[0]

        with torch.no_grad():
            outputs = model(**inputs)

        start_idx = torch.argmax(outputs.start_logits)
        end_idx = torch.argmax(outputs.end_logits) + 1

        answer = tokenizer.convert_tokens_to_string(
            tokenizer.convert_ids_to_tokens(input_ids[start_idx:end_idx])
        )

        return answer.strip() if answer.strip() else "âš ï¸ æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚"

    except Exception as e:
        return f"âŒ é”™è¯¯ï¼š{str(e)}"

# Create Gradio interface
with gr.Blocks(title="ä¸­æ–‡BERTé—®ç­”ç³»ç»Ÿ") as demo:
    gr.Markdown("## ğŸ“˜ ä¸­æ–‡é—®ç­”ç³»ç»Ÿ\nè¯·åœ¨ä¸‹æ–¹åˆ†åˆ«è¾“å…¥ä¸Šä¸‹æ–‡å’Œé—®é¢˜ã€‚")

    with gr.Row():
        context_input = gr.Textbox(label="ğŸ“ ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰", placeholder="è¯·è¾“å…¥å‚è€ƒå†…å®¹â€¦â€¦", lines=6)
        question_input = gr.Textbox(label="â“ é—®é¢˜ï¼ˆQuestionï¼‰", placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜â€¦â€¦", lines=2)

    answer_output = gr.Textbox(label="ğŸ“Œ ç­”æ¡ˆ", lines=2)
    submit_btn = gr.Button("æäº¤")

    submit_btn.click(fn=answer_question, inputs=[context_input, question_input], outputs=answer_output)

# Launch app
demo.launch()



